{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FIRST RNN Ruslan and Ludmila.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "HZnZjgLpEaS_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0GorjmIIEp69",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G25ZUSgWHR_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "plain_file = open('/content/gdrive/My Drive/ML/Rusilud.txt').read()\n",
        "plain_file_len = len(plain_file)\n",
        "\n",
        "vocab_inv = sorted(set(plain_file))\n",
        "vocab = {c: i for i, c in enumerate(vocab_inv)}\n",
        "n_chars = len(vocab)\n",
        "\n",
        "file_lines = plain_file.split('\\n')\n",
        "lines_num = len(file_lines)\n",
        "\n",
        "print('file_len =', plain_file_len)\n",
        "print('lines_num =', lines_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GKfLIdOOHs9s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Функция генерации мини батча. Для того, чтобы слова генерируемый нейронной \n",
        "#сетью были больше похожи на настоящие - начинаем каждый батч с начала строчки\n",
        "\n",
        "#Количество символов в батче\n",
        "chunk_len = 200\n",
        "\n",
        "def random_chunk():\n",
        "    #За начало берем случайную строку\n",
        "    start_index = random.randint(0, lines_num - chunk_len / 10)\n",
        "    #Добавляем к строке новые строки, до тех пор, пока их размер не \n",
        "    #привысит размер минибатча\n",
        "    end_index = start_index\n",
        "    c_chunk_len = len(file_lines[end_index])\n",
        "    while c_chunk_len < chunk_len:\n",
        "      end_index += 1\n",
        "      c_chunk_len += len(file_lines[end_index])\n",
        "    end_index += 1\n",
        "    #Добавляем переводы строки между строками и возвращаем минибатч\n",
        "    return \"\\n\".join(file_lines[start_index:end_index])[:chunk_len]\n",
        "\n",
        "#Проверяем, что все работает как надо \n",
        "print(random_chunk())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "piBK-pt4H3rF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm1 = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.lstm2 = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.lstm3 = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, hidden = self.lstm1(input.view(1, 1, -1), hidden)\n",
        "        output, hidden = self.lstm2(output, hidden)\n",
        "        output, hidden = self.lstm3(output, hidden)\n",
        "        output = self.decoder(output.view(1, -1))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(1, 1, self.hidden_size), torch.zeros(1, 1, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aG43PNY-H9SH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(1, len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[0, c] = vocab[string[c]]\n",
        "    return Variable(tensor)\n",
        "print(char_tensor('Руслан'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WmXxR-O8H_cX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E22wqhVgIDHJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "    hidden = decoder.init_hidden()\n",
        "    prime_input = char_tensor(prime_str)\n",
        "    predicted = prime_str\n",
        "\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = decoder(prime_input[:,p], hidden)\n",
        "    inp = prime_input[:,-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden = decoder(inp, hidden)\n",
        "        \n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        predicted_char = vocab_inv[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = char_tensor(predicted_char)\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YKV4tILIIFsQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time, math\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gjj6cr0NIION",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(inp, target):\n",
        "    hidden = decoder.init_hidden()\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(chunk_len-1):\n",
        "        output, hidden = decoder(inp[:,c], hidden)\n",
        "        loss += criterion(output, target[:,c])\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.data[0] / chunk_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SnesAlEiWtox",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 5000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "hidden_size = 128\n",
        "lr = 0.0005\n",
        "\n",
        "decoder = RNN(n_chars, hidden_size, n_chars)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train(*random_training_set())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "        print(evaluate('Руслан купил ', 200), '\\n')\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oqU128gJINqI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 5000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "hidden_size = 128\n",
        "lr = 0.0005\n",
        "\n",
        "decoder = RNN(n_chars, hidden_size, n_chars)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train(*random_training_set())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "        print(evaluate('Руслан купил ', 200), '\\n')\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xQwgVfnNPaYP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_3Pi6vavYtDJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train(*random_training_set())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "        print(evaluate('Руслан купил ', 200), '\\n')\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P25nIoSh7lXc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(evaluate(prime_str='Руслан любил Людмилу', predict_len=100, temperature=0.8) )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}